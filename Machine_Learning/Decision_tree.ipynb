{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2vLxXHLsyuyKSy8edOd+s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siddharthakhandelwal/My_Projects/blob/main/Machine_Learning/Decision_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement\n",
        "Suppose you are starting a company that grows and sells wild mushrooms.\n",
        "\n",
        "Since not all mushrooms are edible, you'd like to be able to tell whether a given mushroom is edible or poisonous based on it's physical attributes\n",
        "You have some existing data that you can use for this task.\n",
        "Can you use the data to help you identify which mushrooms can be sold safely?\n",
        "\n",
        "Note: The dataset used is for illustrative purposes only. It is not meant to be a guide on identifying edible mushrooms."
      ],
      "metadata": {
        "id": "TSE__JicSyMn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cOCzlW-QOYQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from public_tests import *\n",
        "!pip install utils\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]])\n",
        "y_train = np.array([1,1,0,0,1,0,0,1,1,0])"
      ],
      "metadata": {
        "id": "NJdtp1dKQSbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First few elements of X_train:\\n\", X_train[:5])\n",
        "print(\"Type of X_train:\",type(X_train))"
      ],
      "metadata": {
        "id": "-ld9_2_4QaBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First few elements of y_train:\", y_train[:5])\n",
        "print(\"Type of y_train:\",type(y_train))"
      ],
      "metadata": {
        "id": "s-ZovJ6bQcbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('The shape of X_train is:', X_train.shape)\n",
        "print ('The shape of y_train is: ', y_train.shape)\n",
        "print ('Number of training examples (m):', len(X_train))"
      ],
      "metadata": {
        "id": "FYJ-YA4IQeMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_entropy(y):\n",
        "    entropy = 0.\n",
        "    if len(y)!=0:\n",
        "        p1=len(y[y==1])/len(y)\n",
        "        if p1==0 or p1==1:\n",
        "            entropy=0\n",
        "        else:\n",
        "            entropy=(-p1*np.log2(p1))-((1-p1)*np.log2(1-p1))\n",
        "    return entropy"
      ],
      "metadata": {
        "id": "vbglYxlfQgMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Entropy at root node: \", compute_entropy(y_train))\n",
        "compute_entropy_test(compute_entropy)"
      ],
      "metadata": {
        "id": "6hlCBUFCQqQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(X, node_indices, feature):\n",
        "    left_indices = []\n",
        "    right_indices = []\n",
        "    for i in node_indices:\n",
        "        if X[i][feature]==1:\n",
        "            left_indices.append(i)\n",
        "        else:\n",
        "            right_indices.append(i)\n",
        "    return left_indices, right_indices"
      ],
      "metadata": {
        "id": "M7bhubwqQuwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Case 1\n",
        "\n",
        "root_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "feature = 0\n",
        "\n",
        "left_indices, right_indices = split_dataset(X_train, root_indices, feature)\n",
        "\n",
        "print(\"CASE 1:\")\n",
        "print(\"Left indices: \", left_indices)\n",
        "print(\"Right indices: \", right_indices)\n",
        "generate_split_viz(root_indices, left_indices, right_indices, feature)\n",
        "print()\n",
        "\n",
        "# Case 2\n",
        "\n",
        "root_indices_subset = [0, 2, 4, 6, 8]\n",
        "left_indices, right_indices = split_dataset(X_train, root_indices_subset, feature)\n",
        "\n",
        "print(\"CASE 2:\")\n",
        "print(\"Left indices: \", left_indices)\n",
        "print(\"Right indices: \", right_indices)\n",
        "generate_split_viz(root_indices_subset, left_indices, right_indices, feature)\n",
        "split_dataset_test(split_dataset)"
      ],
      "metadata": {
        "id": "zgVwFAdRQ2-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_information_gain(X, y, node_indices, feature):\n",
        "    left_indices, right_indices = split_dataset(X, node_indices, feature)\n",
        "    X_node, y_node = X[node_indices], y[node_indices]\n",
        "    X_left, y_left = X[left_indices], y[left_indices]\n",
        "    X_right, y_right = X[right_indices], y[right_indices]\n",
        "    information_gain = 0\n",
        "    node_entropy=compute_entropy(y_node)\n",
        "    left_entropy=compute_entropy(y_left)\n",
        "    right_entropy=compute_entropy(y_right)\n",
        "\n",
        "    w_left=len(X_left)/len(X_node)\n",
        "    w_right=len(X_right)/len(X_node)\n",
        "\n",
        "    weighted_entropy=w_left*left_entropy+w_right*right_entropy\n",
        "    information_gain=node_entropy-weighted_entropy\n",
        "\n",
        "    return information_gain"
      ],
      "metadata": {
        "id": "6ldIZJwqRBmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info_gain0 = compute_information_gain(X_train, y_train, root_indices, feature=0)\n",
        "print(\"Information Gain from splitting the root on brown cap: \", info_gain0)\n",
        "\n",
        "info_gain1 = compute_information_gain(X_train, y_train, root_indices, feature=1)\n",
        "print(\"Information Gain from splitting the root on tapering stalk shape: \", info_gain1)\n",
        "\n",
        "info_gain2 = compute_information_gain(X_train, y_train, root_indices, feature=2)\n",
        "print(\"Information Gain from splitting the root on solitary: \", info_gain2)\n",
        "\n",
        "compute_information_gain_test(compute_information_gain)"
      ],
      "metadata": {
        "id": "P8loyq2MRLnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_best_split(X, y, node_indices):\n",
        "    num_features = X.shape[1]\n",
        "    best_feature = -1\n",
        "    max_info_gain=0\n",
        "    for feature in range(num_features):\n",
        "        info_gain=compute_information_gain(X,y,node_indices,feature)\n",
        "        if info_gain>max_info_gain:\n",
        "            max_info_gain=info_gain\n",
        "            best_feature=feature\n",
        "\n",
        "    return best_feature"
      ],
      "metadata": {
        "id": "-5WlpVE8RRDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_feature = get_best_split(X_train, y_train, root_indices)\n",
        "print(\"Best feature to split on: %d\" % best_feature)\n",
        "get_best_split_test(get_best_split)"
      ],
      "metadata": {
        "id": "V-uMqhKGRYg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = []\n",
        "def build_tree_recursive(X, y, node_indices, branch_name, max_depth, current_depth):\n",
        "    if current_depth == max_depth:\n",
        "        formatting = \" \"*current_depth + \"-\"*current_depth\n",
        "        print(formatting, \"%s leaf node with indices\" % branch_name, node_indices)\n",
        "        return\n",
        "    best_feature = get_best_split(X, y, node_indices)\n",
        "\n",
        "    formatting = \"-\"*current_depth\n",
        "    print(\"%s Depth %d, %s: Split on feature: %d\" % (formatting, current_depth, branch_name, best_feature))\n",
        "\n",
        "    left_indices, right_indices = split_dataset(X, node_indices, best_feature)\n",
        "    tree.append((left_indices, right_indices, best_feature))\n",
        "\n",
        "    build_tree_recursive(X, y, left_indices, \"Left\", max_depth, current_depth+1)\n",
        "    build_tree_recursive(X, y, right_indices, \"Right\", max_depth, current_depth+1)"
      ],
      "metadata": {
        "id": "TtCTbG4FRbmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_tree_recursive(X_train, y_train, root_indices, \"Root\", max_depth=2, current_depth=0)\n",
        "generate_tree_viz(root_indices, y_train, tree)"
      ],
      "metadata": {
        "id": "qsbZjo08RkSe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}